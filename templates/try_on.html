{% extends 'base.html' %}
{% block content %}
<style>
#video, #overlayCanvas {
    max-width: 100%;
    display: block;
}

.container {
    padding: 15px;
}

@media (max-width: 768px) {
    #video, #overlayCanvas {
        height: auto;
    }
}

.video-container {
    position: relative;
    background: #f0f8ff;
    border: 3px solid #007bff;
    border-radius: 10px;
    padding: 15px;
}

.accessory-container {
    background: #e9f5ff;
    border: 3px solid #007bff;
    border-radius: 10px;
    padding: 20px;
    max-height: 50vh;
    overflow-y: auto;
}

.video-wrapper {
    position: relative;
    width: 100%;
    height: 100%;
}

.go-back-btn {
    background-color: #007bff;
    color: white;
    padding: 10px 20px;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    font-size: 16px;
    text-align: center;
    display: block;
    margin: 20px auto;
    width: fit-content;
    transition: background-color 0.3s;
}

.go-back-btn:hover {
    background-color: #0056b3;
}

</style>

<h2 class="text-center mb-4">Try On Accessories with Webcam</h2>

<div class="container">
  <div class="row flex-lg-row flex-column justify-content-between">
    <!-- Video feed section -->
    <div class="col-lg-7 col-md-12 d-flex justify-content-center align-items-center video-container">
      <!-- Video feed -->
      <div class="video-wrapper">
        <video id="video" autoplay muted playsinline 
               style="transform: scaleX(-1); width: 100%; height: auto; display: block;"></video>
        <!-- Canvas for drawing accessories -->
        <canvas id="overlayCanvas" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></canvas>
      </div>
    </div>

    <!-- Accessories selection section -->
    <div class="col-lg-4 col-md-12 accessory-container mt-lg-0 mt-4" >
      <h4 class="text-center mb-3">Select an Accessory to Try On:</h4>
      <div class="d-flex flex-wrap overflow-y-lg-auto accessory-selection" style="max-height: 33vh; max-width: 100vw;">
        {% for accessory in accessories %}
        <div class="col-lg-6 col-md-4 col-6 text-center mb-4">
          <img
            src="{{ url_for('static', filename='accessories/' + accessory.image) }}"
            class="img-fluid"
            alt="{{ accessory.name }}"
            width="100"
            height="100"
            style="cursor: pointer; border: 1px solid #007bff; border-radius: 10px; padding: 2px; transition: transform 0.3s ease;"
            onmouseover="this.style.transform='scale(1.1)';"
            onmouseout="this.style.transform='scale(1)';"
            onclick="tryOnAccessory('{{ accessory.name }}', '{{ accessory.type }}', '{{ url_for('static', filename='accessories/' + accessory.image) }}')"
          />
          <p class="mt-2"><strong>{{ accessory.name }}</strong></p>
          <p class="text-muted">{{ accessory.type }}</p>
        </div>
        {% endfor %}
      </div>
    </div>
  </div>
  <div class="row justify-content-between mb-4">
  <!-- Go Back Button -->
  <button class="go-back-btn" onclick="window.location.href='/'">Back to Menu</button>
  <!-- Capture Button -->
<button id="captureButton" class="go-back-btn">Capture and Save</button>
  </div>
</div>

<script>
function initializeApp() {
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlayCanvas');
    const ctx = canvas.getContext('2d');
    const captureButton = document.getElementById('captureButton');
    let selectedAccessory = null;

    // Load the face-api.js models
    Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri('/static/models'),
        faceapi.nets.faceLandmark68Net.loadFromUri('/static/models'),
        faceapi.nets.faceRecognitionNet.loadFromUri('/static/models')
    ]).then(startVideo);

    // Start the webcam video feed
    function startVideo() {
        navigator.mediaDevices.getUserMedia({ video: {} })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => console.error(err));
    }

    // Adjust canvas size to match video dimensions
    function resizeCanvas() {
        const videoBounds = video.getBoundingClientRect();
        canvas.width = videoBounds.width;
        canvas.height = videoBounds.height;
        canvas.style.width = `${videoBounds.width}px`;
        canvas.style.height = `${videoBounds.height}px`;
    }

    // Resize canvas when the video starts
    video.addEventListener('loadedmetadata', () => {
        resizeCanvas();
        window.addEventListener('resize', resizeCanvas); // Resize on window resize
    });

    // Process the video feed
    video.addEventListener('play', () => {
        const displaySize = { width: video.videoWidth, height: video.videoHeight };

        // Run detection and draw accessories periodically
        setInterval(async () => {
            const detections = await faceapi
                .detectAllFaces(video)
                .withFaceLandmarks();

            const resizedDetections = faceapi.resizeResults(detections, displaySize);

            // Clear the canvas and prepare for drawing
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (detections.length > 0) {
                overlayAccessory(ctx, resizedDetections[0], displaySize);
            }
        }, 100);
    });

    // Handle accessory selection
    window.tryOnAccessory = function (name, type, image) {
        selectedAccessory = { name, type, image };
        console.log(`Selected Accessory: ${JSON.stringify(selectedAccessory)}`);
    };

    // Function to overlay the accessory on the face and show facial feature points
    function overlayAccessory(ctx, detection, displaySize) {
        if (!selectedAccessory) return;

        const accessoryImage = new Image();
        accessoryImage.src = selectedAccessory.image;

        accessoryImage.onload = () => {
            const landmarks = detection.landmarks;
            const faceBox = detection.detection.box; // Bounding box of the face

            const xScale = canvas.width / video.videoWidth;
            const yScale = canvas.height / video.videoHeight;
            const faceScaleFactor = faceBox.width / 80;

            const accessoryWidth = 150 * xScale * faceScaleFactor;
            const accessoryHeight = 100 * yScale * faceScaleFactor;

            ctx.save();
            ctx.translate(canvas.width, 0);
            ctx.scale(-1, 1);

            if (selectedAccessory.type === 'headwear') {
                const leftEye = landmarks.getLeftEye()[0];
                const rightEye = landmarks.getRightEye()[3];

                const foreheadX = ((leftEye.x + rightEye.x) / 2 - 10) * xScale;
                const foreheadY = (leftEye.y - 90) * yScale;

                ctx.drawImage(accessoryImage, foreheadX - accessoryWidth / 2, foreheadY - accessoryHeight / 2, accessoryWidth, accessoryHeight);
            }
            ctx.restore();
        };
    }

    // Add functionality to capture the image
    captureButton.addEventListener('click', () => {
        const captureCanvas = document.createElement('canvas');
        const captureCtx = captureCanvas.getContext('2d');

        // Set canvas size to match video dimensions
        captureCanvas.width = video.videoWidth;
        captureCanvas.height = video.videoHeight;

        // Draw video frame
        captureCtx.drawImage(video, 0, 0, captureCanvas.width, captureCanvas.height);

        // Draw the accessory overlay
        captureCtx.drawImage(canvas, 0, 0, captureCanvas.width, captureCanvas.height);

        // Create a link element to download the image
        const dataUrl = captureCanvas.toDataURL('image/png');
        const link = document.createElement('a');
        link.href = dataUrl;
        link.download = 'captured_image.png';
        link.click();

        alert('Image captured and downloaded!');
    });
}


</script>
<script
  src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"
  onload="initializeApp()"
></script>

{% endblock %}
